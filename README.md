


# Як використовувати FlinkSQL з Kafka, Streamlit та API Alpaca

*Тсс. Симуляція цього додатку зараз розгорнута за адресою https://st-flink-kafka-simulation.streamlit.app/*

Дізнайтеся, як використовувати ці 4 технології разом, запустивши цю демонстрацію самостійно!

У цьому проєкті ви генеруватимете події торгівлі акціями з вебсокета ринків Alpaca API до теми Apache Kafka, розташованої в Confluent Cloud. Далі використовуйте FlinkSQL у Confluent Cloud для створення 5-секундних середніх значень цін на акції у вікні, що перекидається (tumbling window). Потім ви споживатимете середні значення з резервної теми Kafka та відображатимете їх за допомогою Streamlit.

*Графік 4 технологій*

**Примітка:** Хоча в майбутньому це може змінитися, на момент написання цього README NYSE працює з 9:30 до 16:00 за EST. Якщо ви запустите цю програму поза цими годинами, ви можете не побачити даних.

## Крок 1: Налаштування в Confluent Cloud

Зареєструйтеся в Confluent Cloud.

### Щоб додати середовище:
1. Відкрийте консоль Confluent Cloud і перейдіть на сторінку середовищ за адресою https://confluent.cloud/environments.
2. Натисніть 'Додати хмарне середовище'.
3. Введіть назву середовища: stocks_environment
4. Натисніть 'Створити'.
5. Пропустіть будь-які підказки чи опції для управління потоком.

### Потім створіть кластер у своєму середовищі:
1. Натисніть 'Додати кластер'.
2. На сторінці 'Створити кластер' для 'Базового' кластера виберіть 'Почати налаштування'.
3. Коли вам буде запропоновано вибрати провайдера та розташування, виберіть us-east-2 від AWS.
4. Виберіть 'Продовжити'.
5. Вкажіть назву кластера, перегляньте інформацію про конфігурацію та вартість, а потім виберіть 'Запустити кластер'.
6. Залежно від обраного хмарного провайдера та інших налаштувань, забезпечення кластера може зайняти кілька хвилин, але після цього з'явиться сторінка 'Огляд кластера'.

### Створіть ключ API Confluent Cloud і збережіть його:
**Примітка:** якщо у вас більше одного середовища, дотримуйтесь другого набору інструкцій нижче.

1. У меню 'Адміністрування' натисніть 'Ключі Cloud API' або перейдіть за посиланням https://confluent.cloud/settings/api-keys.
2. Натисніть 'Додати ключ'.
3. Виберіть створення ключа, пов'язаного з вашим обліковим записом.
4. Будуть створені та показані ключ та секрет API.
5. Натисніть 'Копіювати', щоб скопіювати ключ і секрет у безпечне місце.

**Важливо**

Секрет для ключа відображається лише на початку в діалоговому вікні створення ключа API і його неможливо переглянути чи отримати пізніше з веб-інтерфейсу. Зберігайте секрет і відповідний ключ у безпечному місці. Не діліться секретом вашого ключа API.

6. (Необов'язково, але рекомендовано) Введіть опис ключа API, що описує, як ви плануєте його використовувати, щоб відрізнити від інших ключів API.
7. Виберіть прапорець підтвердження, що ви зберегли ключ і секрет.
8. Натисніть 'Зберегти'. Ключ додається до таблиці ключів.

### Інструкції, якщо у вас більше одного середовища:
1. Перейдіть на сторінку середовищ за адресою https://confluent.cloud/environments і виберіть середовище.
2. Виберіть кластер.
3. Виберіть 'Ключі API' в розділі 'Огляд кластера'.
4. Натисніть '+ Додати ключ'. Будуть створені та показані ключ та секрет API.
5. Натисніть 'Копіювати', щоб скопіювати ключ і секрет у безпечне місце.

Секрет для ключа відображається лише в діалоговому вікні 'Створити ключ API' і його неможливо переглянути чи отримати пізніше. Зберігайте ключ API та секрет у безпечному місці. Не діліться секретом вашого ключа API.

6. (Необов'язково, але рекомендовано) Введіть опис ключа API, що описує, як ви плануєте його використовувати, щоб відрізнити від інших ключів API. Підтвердіть, що ви зберегли ключ і секрет.
7. Натисніть 'Продовжити'. Ключ додається до таблиці ключів API.

### Створіть 1 тему з 1 розділом з назвою SPY:
1. З навігаційного меню натисніть 'Теми', а потім 'Створити тему'.
2. У полі назви теми введіть "SPY". Змініть поле 'Розділи' з 6 на 1. Потім виберіть 'Створити за замовчуванням'.

### Створіть ключ API для Schema Registry:
1. У середовищі, для якого ви хочете налаштувати Schema Registry, знайдіть 'Облікові дані' на правій бічній панелі та натисніть на ключі, щоб відкрити діалогове вікно API облікових даних. (Якщо ви тільки починаєте, натисніть 0 ключів.)
2. Натисніть 'Додати ключ', щоб створити новий ключ API для Schema Registry.
3. Коли ключ API та секрет API будуть збережені, натисніть прапорець поруч із 'Я зберіг свій ключ API та секрет і готовий продовжити', а потім натисніть 'Продовжити'. Ваш новий ключ Schema Registry відображається у списку ключів доступу API Schema Registry.

### Для теми встановіть схему JSON:
1. З навігаційного меню натисніть 'Теми', потім натисніть на тему, щоб вибрати її (або створіть нову).
2. Натисніть вкладку 'Схема'.
3. Натисніть 'Встановити схему'. З'явиться редактор схеми.
4. Виберіть тип схеми: JSON.
5. Основна структура схеми з'являється попередньо заповненою в редакторі як початкова точка. Видаліть та введіть наступну схему в редакторі:

```json
{
  "$id": "http://example.com/myURI.schema.json",
  "$schema": "http://json-schema.org/draft-07/schema#",
  "additionalProperties": false,
  "description": "Sample schema to help you get started.",
  "properties": {
    "bid_timestamp": {
      "description": "The string type is used for strings of text.",
      "type": "string"
    },
    "price": {
      "description": "JSON number type.",
      "type": "number"
    },
    "symbol": {
      "description": "The string type is used for strings of text.",
      "type": "string"
    }
  },
  "title": "SampleRecord",
  "type": "object"
}
```

6. Натисніть Створити.

Вам знадобляться два URL-адреси пізніше. URL-адреса вашого bootstrap-сервера можна знайти в розділі Огляд кластера -> Налаштування кластера, а URL-адреса вашого Schema Registry знаходиться в розділі Середовища -> stocks_environments

### Створіть пул обчислень Flink:
1. У навігаційному меню натисніть 'Середовища' та натисніть плитку для середовища, де ви хочете використовувати Flink SQL.
2. На сторінці деталей середовища натисніть 'Flink'.
3. На сторінці Flink натисніть 'Обчислювальні пули', якщо він ще не вибраний.
4. Натисніть 'Створити обчислювальний пул', щоб відкрити сторінку 'Створити обчислювальний пул'.
5. У випадаючому списку 'Регіон' виберіть регіон, де розміщені дані, які ви хочете обробляти за допомогою SQL. Натисніть 'Продовжити'.

**Важливо**

Цей регіон повинен бути таким самим, як той, у якому ви створили свій кластер, тобто us-east-2 від AWS

6. У текстовому полі 'Назва пулу' введіть "stocks-compute-pool".
7. У випадаючому списку 'Макс. CFU' виберіть 10.
8. Натисніть 'Продовжити', а на сторінці 'Перегляд і створення' натисніть 'Завершити'.

На сторінці Flink з'явиться плитка для вашого обчислювального пулу. Вона показує пул у стані Provisioning.

Може зайняти кілька хвилин, поки пул перейде у стан Running.

### Запустіть FlinkSQL
1. У комірці нового робочого простору ви можете почати виконувати SQL-запити. Скопіюйте та вставте цей оператор у робочий простір:

```sql
CREATE TABLE tumble_interval_SPY
(`symbol` STRING, `window_start` STRING,`window_end` STRING,`price` DOUBLE, PRIMARY KEY (`symbol`) NOT ENFORCED)
DISTRIBUTED BY (symbol) INTO 1 BUCKETS 
WITH ('value.format' = 'json-registry');
```

2. Натисніть 'Запустити'.
Вищенаведений оператор створює таблицю Flink з полями, що вказують на кінець і початок вікна, та ціною для кожного кінця та початку.

3. Вам також потрібно буде виконати цей оператор. Натисніть символ '+', щоб додати оператор у робочому просторі.

```sql
INSERT INTO tumble_interval_SPY
SELECT symbol, DATE_FORMAT(window_start,'yyyy-MM-dd hh:mm:ss.SSS'), DATE_FORMAT(window_end,'yyyy-MM-dd hh:mm:ss.SSS'), AVG(price)
FROM TABLE(
        TUMBLE(TABLE SPY, DESCRIPTOR($rowtime), INTERVAL '5' SECONDS))
GROUP BY
    symbol,
    window_start,
    window_end;
```

Вищенаведений оператор вставляє дані в таблицю, яку ви щойно створили. Кожні п'ять секунд він бере середнє значення для ціни акцій SPY і додає його до таблиці tumble_interval_SPY.

**Примітка:** дані не з'являться в цих темах Kafka або таблицях Flink, доки ви не запустите додаток.

## Крок 2: Ваші облікові дані Alpaca
Вам потрібно зареєструватися в Alpaca, щоб отримати ключ.

1. Перейдіть за посиланням https://app.alpaca.markets.
2. Вам не потрібно надавати податковий ідентифікатор або заповнювати іншу інформацію про обліковий запис, щоб отримати ключ для паперової торгівлі.
3. Створіть ключ за допомогою віджета, який ви знайдете праворуч на головній сторінці. Це ключ/секрет, який ви додаватимете до додатку.

## Крок 3: Початок роботи з додатком
```bash
git clone https://github.com/Cerchie/finnhub.git && cd finnhub
```

потім

```bash
pip install -r requirements.txt
```

Тепер створіть файл у кореневому каталозі з назвою .streamlit/secrets.toml (ця початкова крапка є частиною конвенції).

У ньому вам знадобиться:

```toml
ALPACA_KEY = "your_alpaca_key"
ALPACA_SECRET = "your_alpaca_secret"
SASL_USERNAME = "your_confluent_cloud_api_key"
SASL_PASSWORD = "your_confluent_cloud_api_secret"
SR_URL = "your_confluent_cloud"
BASIC_AUTH_USER_INFO = "your_confluent_cloud_schema_registry_key:your_confluent_cloud_schema_registry_secret"
BOOTSTRAP_URL = "your_confluent_cloud_bootstrap_url"
```

Зверніть увагу, що двокрапка (:) необхідна для BASIC_AUTH_USER_INFO.

Вам також знадобиться обліковий запис Streamlit, щоб секрети були в середовищі.

Тепер виконайте `streamlit run app.py` у вашому кореневому каталозі, щоб запустити додаток.

Щоб розгорнути на Streamlit самостійно, дотримуйтесь інструкцій тут і обов'язково включіть секрети в налаштуваннях.

## Крок 4: Вивільнення ресурсів у Confluent Cloud
Щоб уникнути марнування ресурсів після виконання цієї вправи, ви можете розібрати своє середовище в Confluent Cloud. Для цього перейдіть на сторінку свого середовища та натисніть 'Видалити' у правому нижньому куті. Це видалить ваше середовище та його ресурси.
